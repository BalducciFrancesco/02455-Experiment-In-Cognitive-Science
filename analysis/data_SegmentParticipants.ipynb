{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ced18f8-d771-4049-8cb3-3e282eb099ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: test39_39_20251126_145748_IBI.csv\n",
      "  → Extracting participant 23 (2025-11-26 14:57:00 to 2025-11-26 15:12:00)\n",
      "    ✓ Saved participants_split_sensor11/participant23.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ==========================================================\n",
    "# 1. Load Firstbeat file function (UNCHANGED)\n",
    "# ==========================================================\n",
    "def load_firstbeat_file(path):\n",
    "    \"\"\"\n",
    "    Reads a Firstbeat IBI file where:\n",
    "    - first 2 lines are metadata\n",
    "    - third line is \"RR;Artifact corrected RR;Raw artifact;\"\n",
    "    - all rows contain semicolon-separated values in ONE column\n",
    "\n",
    "    Returns:\n",
    "        df (DataFrame with RR, ArtifactCorrectedRR, RawArtifact, ts_raw)\n",
    "        raw_start_ts (datetime of header start time)\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1. Read header lines\n",
    "    # ----------------------------------------------------\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Extract raw start time (\"Start time: dd.mm.yyyy HH:MM:SS\")\n",
    "    raw_start_str = lines[1].split(\"Start time:\")[1].strip()\n",
    "    raw_start_ts = datetime.strptime(raw_start_str, \"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 2. Read the data as ONE COLUMN of text\n",
    "    # ----------------------------------------------------\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        header=None,\n",
    "        skiprows=3,\n",
    "        names=[\"raw\"],\n",
    "        dtype=str,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "\n",
    "    # Remove empty lines\n",
    "    df = df[df[\"raw\"].notna() & (df[\"raw\"].str.strip() != \"\")]\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 3. Split \"RR;ArtifactCorrectedRR;RawArtifact\"\n",
    "    # ----------------------------------------------------\n",
    "    raw_split = df[\"raw\"].str.split(\";\", expand=True)\n",
    "\n",
    "    # Keep first 3 columns only\n",
    "    raw_split = raw_split.iloc[:, :3]\n",
    "    raw_split.columns = [\"RR\", \"ArtifactCorrectedRR\", \"RawArtifact\"]\n",
    "\n",
    "    # Convert values to numeric\n",
    "    raw_split[\"RR\"] = pd.to_numeric(raw_split[\"RR\"], errors=\"coerce\")\n",
    "    raw_split[\"ArtifactCorrectedRR\"] = pd.to_numeric(raw_split[\"ArtifactCorrectedRR\"], errors=\"coerce\")\n",
    "    raw_split[\"RawArtifact\"] = pd.to_numeric(raw_split[\"RawArtifact\"], errors=\"coerce\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 4. DROP rows where corrected RR is NaN\n",
    "    #    (Firstbeat sometimes leaves the last line empty)\n",
    "    # ----------------------------------------------------\n",
    "    raw_split = raw_split.dropna(subset=[\"ArtifactCorrectedRR\"]).reset_index(drop=True)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 5. Compute raw timestamps with cumsum over RR intervals\n",
    "    # ----------------------------------------------------\n",
    "    rr_seconds = raw_split[\"ArtifactCorrectedRR\"] / 1000  # convert ms → seconds\n",
    "    cumulative_time = rr_seconds.cumsum()\n",
    "\n",
    "    # Safe apply to avoid NaN issues\n",
    "    raw_split[\"ts_raw\"] = cumulative_time.apply(\n",
    "        lambda s: raw_start_ts + timedelta(seconds=float(s))\n",
    "    )\n",
    "\n",
    "    return raw_split, raw_start_ts\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 2. Define EXACT extractions you want\n",
    "# ==========================================================\n",
    "\n",
    "EXTRACTIONS = {\n",
    "    #\"test39_39_20251113_125113_IBI.csv\": [7],\n",
    "    #\"test39_39_20251113_132004_IBI.csv\": [8, 10],\n",
    "    #\"test39_39_20251116_140244_IBI.csv\": [14],\n",
    "    \"test39_39_20251126_145748_IBI.csv\": [23],\n",
    "}\n",
    "\n",
    "metadata_path = \"trials_sensor11.csv\"\n",
    "hr_data_folder = \"sensor11/\"\n",
    "output_folder = \"participants_split_sensor11/\"\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "meta = pd.read_csv(metadata_path)\n",
    "meta[\"Date_dt\"] = pd.to_datetime(meta[\"Date\"], format=\"%d-%b-%y\")\n",
    "meta[\"Start_ts\"] = pd.to_datetime(meta[\"Date_dt\"].dt.strftime(\"%Y-%m-%d\") + \" \" + meta[\"Start time (firstbeat)\"])\n",
    "meta[\"End_ts\"]   = pd.to_datetime(meta[\"Date_dt\"].dt.strftime(\"%Y-%m-%d\") + \" \" + meta[\"End time (firstbeat)\"])\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 3. PROCESS ONLY THE FILES + PARTICIPANTS YOU SPECIFIED\n",
    "# ==========================================================\n",
    "\n",
    "for filename, participant_list in EXTRACTIONS.items():\n",
    "\n",
    "    filepath = os.path.join(hr_data_folder, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"❌ File not found: {filepath}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing: {filename}\")\n",
    "\n",
    "    # Extract date from filename\n",
    "    file_date_str = filename.split(\"_\")[2]  # e.g. 20251113\n",
    "    file_date = pd.to_datetime(file_date_str, format=\"%Y%m%d\")\n",
    "\n",
    "    # Metadata for participants on that date\n",
    "    day_meta = meta[meta[\"Date_dt\"] == file_date]\n",
    "\n",
    "    # Load HR file\n",
    "    df_raw, raw_start_ts = load_firstbeat_file(filepath)\n",
    "\n",
    "    # -------------------------\n",
    "    # Process each requested participant\n",
    "    # -------------------------\n",
    "    for pid in participant_list:\n",
    "\n",
    "        row = day_meta[day_meta[\"Participant ID\"] == pid]\n",
    "\n",
    "        if row.empty:\n",
    "            print(f\"  ⚠️ Participant {pid} missing from metadata for {filename}\")\n",
    "            continue\n",
    "\n",
    "        row = row.iloc[0]\n",
    "\n",
    "        start_ts = row[\"Start_ts\"]\n",
    "        end_ts = row[\"End_ts\"]\n",
    "\n",
    "        print(f\"  → Extracting participant {pid} ({start_ts} to {end_ts})\")\n",
    "\n",
    "        # Fix device clock offset\n",
    "        time_offset = start_ts - df_raw[\"ts_raw\"].iloc[0]\n",
    "        df_raw[\"ts\"] = df_raw[\"ts_raw\"] + time_offset\n",
    "\n",
    "        # Slice window\n",
    "        p_df = df_raw[(df_raw[\"ts\"] >= start_ts) & (df_raw[\"ts\"] <= end_ts)]\n",
    "\n",
    "        if p_df.empty:\n",
    "            print(f\"    ⚠️ No HR data found for participant {pid}\")\n",
    "            continue\n",
    "\n",
    "        # Keep columns\n",
    "        clean_df = p_df[[\"RR\", \"ArtifactCorrectedRR\", \"RawArtifact\", \"ts\"]]\n",
    "\n",
    "        # Output file\n",
    "        outpath = os.path.join(output_folder, f\"participant{pid}.csv\")\n",
    "\n",
    "        with open(outpath, \"w\") as f:\n",
    "            f.write(f\"Participant ID: {pid}\\n\")\n",
    "            f.write(f\"Start time: {start_ts}\\n\")\n",
    "            f.write(f\"End time: {end_ts}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        clean_df.to_csv(outpath, mode=\"a\", index=False)\n",
    "\n",
    "        print(f\"    ✓ Saved {outpath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add8156-22c3-4ab2-bcd4-0e398f5b11ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
