{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b891fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "def cohens_d_independent(m1, s1, n1, m2, s2, n2):\n",
    "    # 1. pooled SD\n",
    "    s1_sq = s1**2\n",
    "    s2_sq = s2**2\n",
    "    pooled_var = ((n1-1)*s1_sq + (n2-1)*s2_sq) / (n1+n2-2)\n",
    "    s_pooled = math.sqrt(pooled_var)\n",
    "    \n",
    "    # 2. Cohen's d\n",
    "    diff = m1 - m2\n",
    "    d = diff / s_pooled\n",
    "    \n",
    "    return d\n",
    "\n",
    "# Example\n",
    "m1, s1, n1 = 80, 6, 15    # Group 1: mean, std, n\n",
    "m2, s2, n2 = 75, 6, 15    # Group 2: mean, std, n\n",
    "\n",
    "d = cohens_d_independent(m1, s1, n1, m2, s2, n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc74902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "alpha = 0.05   # type I error rate (1-alpha confidence level)\n",
    "beta = 0.2     # type II error rate (1 - power)\n",
    "norm.ppf(1 - alpha / 2)  # two-tailed z critical value for 95% confidence interval\n",
    "norm.ppf(1 - beta)  # z critical value for 80% power\n",
    "\n",
    "# Sample size calculation for one-sample z-test for mean\n",
    "def calculate_sample_size(d, alpha, beta):\n",
    "    z_alpha = norm.ppf(1 - alpha / 2)  # two-tailed\n",
    "    z_beta = norm.ppf(1 - beta)\n",
    "    n = 2 * (z_alpha + z_beta) ** 2 / d ** 2\n",
    "    return int(n) + 1  # round up to next whole number\n",
    "\n",
    "calculate_sample_size(d, alpha, beta)  # Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c3775",
   "metadata": {},
   "source": [
    "# Experiment design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767d8e2e",
   "metadata": {},
   "source": [
    "Generates a complete experimental design for assigning videos and beliefs to subjects. It creates all possible permutations of video orders (`all_orders`) and assigns random beliefs (`all_beliefs`) to each video for every subject. The design matrix (`design`) combines video order, belief, order index, and subject ID into a structured format. Finally, it prints the design in a tabular format, showing the video, belief, order, and subject for each assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ad8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video\tBelief\t\t\tOrder\tSubject\n",
      "1\tHuman Generated \t1\t1\n",
      "2\tHuman Generated \t2\t1\n",
      "3\tAI Generated    \t3\t1\n",
      "4\tAI Generated    \t4\t1\n",
      "\n",
      "1\tHuman Generated \t1\t2\n",
      "2\tHuman Generated \t2\t2\n",
      "4\tAI Generated    \t3\t2\n",
      "3\tAI Generated    \t4\t2\n",
      "\n",
      "1\tHuman Generated \t1\t3\n",
      "3\tAI Generated    \t2\t3\n",
      "2\tHuman Generated \t3\t3\n",
      "4\tAI Generated    \t4\t3\n",
      "\n",
      "1\tHuman Generated \t1\t4\n",
      "3\tAI Generated    \t2\t4\n",
      "4\tAI Generated    \t3\t4\n",
      "2\tHuman Generated \t4\t4\n",
      "\n",
      "1\tHuman Generated \t1\t5\n",
      "4\tAI Generated    \t2\t5\n",
      "2\tHuman Generated \t3\t5\n",
      "3\tAI Generated    \t4\t5\n",
      "\n",
      "1\tHuman Generated \t1\t6\n",
      "4\tAI Generated    \t2\t6\n",
      "3\tAI Generated    \t3\t6\n",
      "2\tHuman Generated \t4\t6\n",
      "\n",
      "2\tHuman Generated \t1\t7\n",
      "1\tHuman Generated \t2\t7\n",
      "3\tAI Generated    \t3\t7\n",
      "4\tAI Generated    \t4\t7\n",
      "\n",
      "2\tHuman Generated \t1\t8\n",
      "1\tHuman Generated \t2\t8\n",
      "4\tAI Generated    \t3\t8\n",
      "3\tAI Generated    \t4\t8\n",
      "\n",
      "2\tHuman Generated \t1\t9\n",
      "3\tAI Generated    \t2\t9\n",
      "1\tHuman Generated \t3\t9\n",
      "4\tAI Generated    \t4\t9\n",
      "\n",
      "2\tHuman Generated \t1\t10\n",
      "3\tAI Generated    \t2\t10\n",
      "4\tAI Generated    \t3\t10\n",
      "1\tHuman Generated \t4\t10\n",
      "\n",
      "2\tHuman Generated \t1\t11\n",
      "4\tAI Generated    \t2\t11\n",
      "1\tHuman Generated \t3\t11\n",
      "3\tAI Generated    \t4\t11\n",
      "\n",
      "2\tHuman Generated \t1\t12\n",
      "4\tAI Generated    \t2\t12\n",
      "3\tAI Generated    \t3\t12\n",
      "1\tHuman Generated \t4\t12\n",
      "\n",
      "3\tHuman Generated \t1\t13\n",
      "1\tAI Generated    \t2\t13\n",
      "2\tAI Generated    \t3\t13\n",
      "4\tHuman Generated \t4\t13\n",
      "\n",
      "3\tHuman Generated \t1\t14\n",
      "1\tAI Generated    \t2\t14\n",
      "4\tHuman Generated \t3\t14\n",
      "2\tAI Generated    \t4\t14\n",
      "\n",
      "3\tHuman Generated \t1\t15\n",
      "2\tAI Generated    \t2\t15\n",
      "1\tAI Generated    \t3\t15\n",
      "4\tHuman Generated \t4\t15\n",
      "\n",
      "3\tHuman Generated \t1\t16\n",
      "2\tAI Generated    \t2\t16\n",
      "4\tHuman Generated \t3\t16\n",
      "1\tAI Generated    \t4\t16\n",
      "\n",
      "3\tHuman Generated \t1\t17\n",
      "4\tHuman Generated \t2\t17\n",
      "1\tAI Generated    \t3\t17\n",
      "2\tAI Generated    \t4\t17\n",
      "\n",
      "3\tHuman Generated \t1\t18\n",
      "4\tHuman Generated \t2\t18\n",
      "2\tAI Generated    \t3\t18\n",
      "1\tAI Generated    \t4\t18\n",
      "\n",
      "4\tHuman Generated \t1\t19\n",
      "1\tAI Generated    \t2\t19\n",
      "2\tAI Generated    \t3\t19\n",
      "3\tHuman Generated \t4\t19\n",
      "\n",
      "4\tHuman Generated \t1\t20\n",
      "1\tAI Generated    \t2\t20\n",
      "3\tHuman Generated \t3\t20\n",
      "2\tAI Generated    \t4\t20\n",
      "\n",
      "4\tHuman Generated \t1\t21\n",
      "2\tAI Generated    \t2\t21\n",
      "1\tAI Generated    \t3\t21\n",
      "3\tHuman Generated \t4\t21\n",
      "\n",
      "4\tHuman Generated \t1\t22\n",
      "2\tAI Generated    \t2\t22\n",
      "3\tHuman Generated \t3\t22\n",
      "1\tAI Generated    \t4\t22\n",
      "\n",
      "4\tHuman Generated \t1\t23\n",
      "3\tHuman Generated \t2\t23\n",
      "1\tAI Generated    \t3\t23\n",
      "2\tAI Generated    \t4\t23\n",
      "\n",
      "4\tHuman Generated \t1\t24\n",
      "3\tHuman Generated \t2\t24\n",
      "2\tAI Generated    \t3\t24\n",
      "1\tAI Generated    \t4\t24\n",
      "\n",
      "Label counts per video across subjects:\n",
      "Video 1: AI=12, Human=12\n",
      "Video 2: AI=12, Human=12\n",
      "Video 3: AI=12, Human=12\n",
      "Video 4: AI=12, Human=12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "video_values = [\n",
    "    '4171487-uhd_3840_2160_30fps.mp4', \n",
    "    '5768645-uhd_3840_2160_25fps.mp4', \n",
    "    '11946387_3840_2160_30fps.mp4', \n",
    "    '11946387_3840_2160_30fps.mp4'\n",
    "]\n",
    "\n",
    "belief_values = ['AI Generated', 'Human Generated'] # index 0='AI', 1='Human'\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Derive orders (one per subject)\n",
    "# -----------------------------\n",
    "videos = np.arange(1, len(video_values) + 1)  # [1,2,3,4]\n",
    "all_orders = np.array(list(permutations(videos)))  # 24 permutations for 4 videos\n",
    "n_subjects = all_orders.shape[0]\n",
    "\n",
    "# Ensure we can split subjects evenly between the two label strata\n",
    "if n_subjects % 2 != 0:\n",
    "    raise ValueError(\"Number of subjects must be even to split label strata 50/50.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Define the two label strata (by video ID, not by order)\n",
    "# Stratum A: 1,2 = Human ; 3,4 = AI\n",
    "# Stratum B: 1,2 = AI    ; 3,4 = Human\n",
    "# (encode: 0='AI', 1='Human')\n",
    "# -----------------------------\n",
    "label_map_A = np.array([1, 1, 0, 0])  # index 0->video1, etc.\n",
    "label_map_B = 1 - label_map_A         # flips AI/Human for each video\n",
    "\n",
    "# -----------------------------\n",
    "# Build design\n",
    "# -----------------------------\n",
    "subjects = np.repeat(np.arange(1, n_subjects + 1), videos.size)        # 1..24 repeated 4 times\n",
    "orders   = np.tile(np.arange(1, videos.size + 1), n_subjects)          # 1..4 for each subject\n",
    "video_seq = all_orders.flatten()\n",
    "\n",
    "# Pick which subjects use which stratum (first half A, second half B)\n",
    "which_stratum = np.array([0]*(n_subjects//2) + [1]*(n_subjects//2))    # 0=A, 1=B\n",
    "\n",
    "# Compute beliefs per row by applying the subject's stratum map to the video ID\n",
    "belief_codes = []\n",
    "for s_idx in range(n_subjects):\n",
    "    v_ids = all_orders[s_idx]                  # length-4 array of video IDs in that subject's order\n",
    "    lmap = label_map_A if which_stratum[s_idx] == 0 else label_map_B\n",
    "    belief_codes.append(lmap[v_ids - 1])       # map by video ID (1-based -> 0-based index)\n",
    "belief_codes = np.concatenate(belief_codes)\n",
    "\n",
    "# Stack\n",
    "design = np.column_stack((video_seq, belief_codes, orders, subjects))\n",
    "\n",
    "# -----------------------------\n",
    "# Pretty print\n",
    "# -----------------------------\n",
    "print(\"Video\\tBelief\\t\\t\\tOrder\\tSubject\")\n",
    "for i, row in enumerate(design):\n",
    "    video_id, belief_code, ord_idx, subj = row.astype(int)\n",
    "    belief_str = belief_values[belief_code]\n",
    "    print(f\"{video_id}\\t{belief_str:<16}\\t{ord_idx}\\t{subj}\")\n",
    "    if (i + 1) % videos.size == 0:\n",
    "        print()\n",
    "\n",
    "# -----------------------------\n",
    "# Sanity checks (optional): balance per video across subjects\n",
    "# -----------------------------\n",
    "if True:\n",
    "    # For each video, count how many times it's labeled AI/Human across all subjects\n",
    "    counts = {vid: {\"AI\": 0, \"Human\": 0} for vid in videos}\n",
    "    for (vid, bcode) in design[:, :2].astype(int):\n",
    "        if bcode == 0:\n",
    "            counts[vid][\"AI\"] += 1\n",
    "        else:\n",
    "            counts[vid][\"Human\"] += 1\n",
    "    print(\"Label counts per video across subjects:\")\n",
    "    for vid in videos:\n",
    "        print(f\"Video {vid}: AI={counts[vid]['AI']}, Human={counts[vid]['Human']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "345bc9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of subjects: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of subjects:\", len(np.unique(design[:, 3])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a121a04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 4), array([ 240,   58,  240, 1200]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design.shape, design.sum(axis=0)  # Sum of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c2fbc",
   "metadata": {},
   "source": [
    "Outputs the design in a CSV file that can be imported in PsychoPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7080cd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV to: ./subjects_design.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "out_path = \"./subjects_design.csv\"\n",
    "header = [\"video1\",\"label1\",\"video2\",\"label2\",\"video3\",\"label3\",\"video4\",\"label4\"]\n",
    "subjects = np.unique(design[:, 3])\n",
    "with open(out_path, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(header)\n",
    "    for s in subjects:\n",
    "        rows = design[design[:, 3] == s]\n",
    "        rows = rows[rows[:, 2].argsort()]  # sort by Order\n",
    "        row = []\n",
    "        for r in rows:\n",
    "            row.append(video_values[r[0] - 1])  # video\n",
    "            row.append(belief_values[r[1]])     # label/belief\n",
    "        w.writerow(row)\n",
    "print(f\"Saved CSV to: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIhumancog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
